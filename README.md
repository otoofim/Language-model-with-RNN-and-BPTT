# N-gram language model with RNN and BPTT

This code is part of Natural Language Understading course in the university of Edinburgh.

To generate some, almost meaningfull, sentences use command below:

```
python rnn.py generate PATH/data PATH/W LENGHT_OF_THE_SENTENCE
```

### Some must-read tutorials:

Good tutorial on RNN:
http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/
http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/

Charecter level language model (useful to generate code):
http://karpathy.github.io/2015/05/21/rnn-effectiveness/

Creating a text corpus from Wikipedia:
http://trulymadlywordly.blogspot.co.uk/2011/03/creating-text-corpus-from-wikipedia.html
